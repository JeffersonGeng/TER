{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import keras \n","from keras import layers\n","import numpy as np\n","from numba import cuda\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","from tqdm import tqdm\n","import re\n","from keras.utils import img_to_array, plot_model, array_to_img\n","import gc"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def sorted_alphanumeric(data):  \n","    convert = lambda text: int(text) if text.isdigit() else text.lower()\n","    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","    return sorted(data,key = alphanum_key)\n","# defining the size of the image\n","SIZE = 256\n","color_img = []\n","gray_img = []\n","path = 'E:/TER/LandscapeDataResize/color'\n","files = os.listdir(path)\n","files = sorted_alphanumeric(files)\n","for i in tqdm(files):    \n","        if i == '7200.jpg':\n","            break\n","        else:\n","            img = cv2.imread(path + '/'+i,1)\n","            img = cv2.resize(img, (SIZE, SIZE))\n","            # open cv reads images in BGR format so we have to convert it to LAB\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n","            #resizing image\n","            #分离图像通道\n","            l, a, b = cv2.split(img)\n","            xx=b\n","            #归一化\n","            l = (l/ 255.0)\n","            a = (a/ 255.0)\n","            b = (b/ 255.0)\n","            #合并通道\n","            img = cv2.merge([l, a, b])\n","            color_img.append(img_to_array(img))\n","            gray_img.append(img_to_array(l))\n","color_dataset=tf.data.Dataset.from_tensor_slices(np.array(color_img[0:2000])).batch(20)\n","gray_dataset=tf.data.Dataset.from_tensor_slices(np.array(gray_img[0:2000])).batch(20)\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["example_color = next(iter(color_dataset))\n","example_gray = next(iter(gray_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_images(a = 4):\n","    \n","    for i in range(a):\n","        plt.figure(figsize = (10,10))\n","        plt.subplot(121)\n","        plt.title('color')\n","        l, a, b = cv2.split(np.array(example_color[i]))\n","        #归一化\n","        l = (l.astype('float32')* 100)\n","        a = (a.astype('float32')* 255.0)-128\n","        b = (b.astype('float32')* 255.0)-128\n","        #合并通道\n","        color = cv2.merge([l, a, b])\n","        plt.imshow(cv2.cvtColor(color, cv2.COLOR_Lab2RGB))\n","        plt.subplot(122)\n","        plt.title('gray')\n","        plt.imshow(example_gray[i], cmap = 'gray')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_images(3)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def downsample(filters, size, apply_batchnorm=True):\n","  \n","  result = tf.keras.Sequential()\n","  result.add(\n","      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n","                             kernel_initializer='he_normal', use_bias=False))\n","\n","  if apply_batchnorm:\n","    result.add(tf.keras.layers.BatchNormalization())\n","\n","  result.add(tf.keras.layers.LeakyReLU())\n","\n","  return result\n","\n","def upsample(filters, size, apply_dropout=False):\n","  \n","\n","  result = tf.keras.Sequential()\n","  result.add(\n","    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n","                                    padding='same',\n","                                    kernel_initializer='he_normal',\n","                                    use_bias=False))\n","\n","  result.add(tf.keras.layers.BatchNormalization())\n","\n","  if apply_dropout:\n","      result.add(tf.keras.layers.Dropout(0.5))\n","\n","  result.add(tf.keras.layers.ReLU())\n","\n","  return result  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def Generator():\n","  inputs = tf.keras.layers.Input(shape=[256,256,1])\n","\n","  down_stack = [\n","    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n","    downsample(128, 4), # (bs, 64, 64, 128)\n","    downsample(256, 4), # (bs, 32, 32, 256)\n","    downsample(512, 4), # (bs, 16, 16, 512)\n","    downsample(512, 4), # (bs, 8, 8, 512)\n","    downsample(512, 4), # (bs, 4, 4, 512)\n","    downsample(512, 4), # (bs, 2, 2, 512)\n","    downsample(512, 4), # (bs, 1, 1, 512)\n","  ]\n","\n","  up_stack = [\n","    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n","    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n","    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n","    upsample(512, 4), # (bs, 16, 16, 1024)\n","    upsample(256, 4), # (bs, 32, 32, 512)\n","    upsample(128, 4), # (bs, 64, 64, 256)\n","    upsample(64, 4), # (bs, 128, 128, 128)\n","  ]\n","\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","  last = tf.keras.layers.Conv2DTranspose(3, 4,\n","                                         strides=2,\n","                                         padding='same',\n","                                         kernel_initializer=initializer,\n","                                         activation='tanh') # (bs, 256, 256, 3)\n","\n","  x = inputs\n","\n","  # Downsampling through the model\n","  skips = []\n","  for down in down_stack:\n","    x = down(x)\n","    skips.append(x)\n","\n","  skips = reversed(skips[:-1])\n","\n","  # Upsampling and establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    x = tf.keras.layers.Concatenate()([x, skip])\n","\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def Discriminator():\n","  initializer = tf.random_normal_initializer(0., 0.02)\n","\n","  inp = tf.keras.layers.Input(shape=[256, 256, 1], name='input_image')\n","  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n","\n","  x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n","\n","  down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n","  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n","  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n","\n","  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n","  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n","                                kernel_initializer=initializer,\n","                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n","\n","  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n","\n","  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n","\n","  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n","\n","  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n","                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n","\n","  return tf.keras.Model(inputs=[inp, tar], outputs=last)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator = Generator()\n","generator.summary()\n","plot_model(generator, to_file='generator_lab.png', show_shapes=True, show_layer_names=True, dpi=320)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["discriminator = Discriminator()\n","discriminator.summary()\n","plot_model(discriminator, to_file='discriminator_lab.png', show_shapes=True, show_layer_names=True, dpi=320)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","LAMBDA = 100\n","\n","def generator_loss(disc_generated_output, gen_output, target):\n","  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n","\n","  # mean absolute error\n","  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n","\n","  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n","\n","  return total_gen_loss, gan_loss, l1_loss\n","\n","def discriminator_loss(disc_real_output, disc_generated_output):\n","  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n","\n","  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n","\n","  total_disc_loss = real_loss + generated_loss\n","\n","  return total_disc_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_images(model, test_input, tar, n=0):\n","  prediction = model(test_input, training=False)\n","  plt.figure(figsize=(15,5))\n","  l, a, b = cv2.split(np.array(tar[0]))\n","  #归一化\n","  l = (l.astype('float32')* 100)\n","  a = (a.astype('float32')* 255.0)-128\n","  b = (b.astype('float32')* 255.0)-128\n","  #合并通道\n","  target_image = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2RGB)  \n","  l, a, b = cv2.split(np.array(prediction[0]))\n","  #归一化\n","  l = (l.astype('float32')* 100)\n","  a = (a.astype('float32')* 255.0)-128\n","  b = (b.astype('float32')* 255.0)-128\n","  #合并通道\n","  prediction_image = cv2.cvtColor(cv2.merge([l, a, b]), cv2.COLOR_LAB2RGB)\n","  display_list = [test_input[0], target_image, prediction_image]\n","  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n","  M = tf.keras.losses.MeanSquaredError()\n","  MSE = M(tar[0], prediction[0])\n","  for i in range(3):\n","    plt.subplot(1, 3, i+1)\n","    plt.title(title[i])\n","    # getting the pixel values between [0, 1] to plot it.\n","    plt.imshow(display_list[i],cmap='gray')\n","    plt.axis('off')\n","  plt.suptitle(\"MSE: \"+str(MSE.numpy()), fontsize=20)\n","  plt.imsave('E:/TER/Result_pix2pix_LandscapeDataResize_LAB/output/'+str(n)+\".png\", prediction_image)\n","  plt.savefig('E:/TER/Result_pix2pix_LandscapeDataResize_LAB/plot/')\n","  plt.show()\n","  plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["@tf.function\n","def train_step(input_image, target, epoch):\n","  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","    gen_output = generator(input_image, training=True)\n","\n","    disc_real_output = discriminator([input_image, target], training=True)\n","    disc_generated_output = discriminator([input_image, gen_output], training=True)\n","\n","    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n","    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n","\n","  generator_gradients = gen_tape.gradient(gen_total_loss,\n","                                          generator.trainable_variables)\n","  discriminator_gradients = disc_tape.gradient(disc_loss,\n","                                               discriminator.trainable_variables)\n","\n","  generator_optimizer.apply_gradients(zip(generator_gradients,\n","                                          generator.trainable_variables))\n","  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n","                                              discriminator.trainable_variables))\n","  return gen_total_loss, disc_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import time\n","def fit(epochs):\n","  gen_loss=[]\n","  dis_loss=[]\n","  for epoch in range(epochs):\n","    result_gen_loss=[]\n","    result_disc_loss=[]\n","    start = time.time()\n","    print(\"Epoch: \"+ str(epoch+1), end=\"\\r\")\n","    # Train\n","    color_dataset=tf.data.Dataset.from_tensor_slices(np.array(color_img[0:2000])).batch(16)\n","    gray_dataset=tf.data.Dataset.from_tensor_slices(np.array(gray_img[0:2000])).batch(16)\n","    for n, (input_image, target) in tf.data.Dataset.zip((gray_dataset, color_dataset)).enumerate():\n","      result_g,result_d=train_step(input_image, target, epoch)\n","      result_gen_loss.append(result_g)\n","      result_disc_loss.append(result_d)\n","    del color_dataset\n","    del gray_dataset\n","    gc.collect()\n","    color_dataset=tf.data.Dataset.from_tensor_slices(np.array(color_img[2000:4000])).batch(16)\n","    gray_dataset=tf.data.Dataset.from_tensor_slices(np.array(gray_img[2000:4000])).batch(16)\n","    for n, (input_image, target) in tf.data.Dataset.zip((gray_dataset, color_dataset)).enumerate():\n","      result_g,result_d=train_step(input_image, target, epoch)\n","      result_gen_loss.append(result_g)\n","      result_disc_loss.append(result_d)\n","    generator.compile()\n","    discriminator.compile()\n","    generator.save('E:/TER/model/generator_lab.h5')\n","    discriminator.save('E:/TER/model/discriminator_lab.h5')\n","    del color_dataset\n","    del gray_dataset\n","    gc.collect()\n","    gen_loss.append(np.mean(result_gen_loss))\n","    dis_loss.append(np.mean(result_disc_loss))\n","    print ('Time taken for epoch {} is {} sec. Generator loss: {} discriminator loss: {}'.format(epoch + 1, time.time()-start,np.mean(result_gen_loss),np.mean(result_disc_loss)))\n","  return gen_loss,dis_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if not os.path.exists('E:/TER/Result_pix2pix_LandscapeDataResize_LAB/output/'):\n","    os.makedirs('E:/TER/Result_pix2pix_LandscapeDataResize_LAB/output/')\n","if not os.path.exists('E:/TER/Result_pix2pix_LandscapeDataResize_LAB/plot/'):\n","    os.makedirs('E:/TER/Result_pix2pix_LandscapeDataResize_LAB/plot/')\n","for example_input, example_target in tf.data.Dataset.zip((gray_dataset,color_dataset)).take(2):\n","  generate_images(generator, example_input, example_target)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gen_loss,dis_loss=fit(epochs = 100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.subplot(1, 2, 1)\n","plt.plot(gen_loss)\n","plt.title('Generator loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.subplot(1, 2, 2)\n","plt.plot(dis_loss)\n","plt.title('Discriminator loss')\n","plt.xlabel('epoch')\n","plt.savefig('./GAN_lab_loss.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["color_dataset_t=tf.data.Dataset.from_tensor_slices(np.array(color_img[4000:])).batch(1)\n","gray_dataset_t=tf.data.Dataset.from_tensor_slices(np.array(gray_img[4000:])).batch(1)\n","n = 0\n","for example_input, example_target in tf.data.Dataset.zip((gray_dataset_t,color_dataset_t)).take(319):\n","  generate_images(generator, example_input, example_target,n)\n","  n+=1"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
